# AI-Powered Interpretations Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Integrate OpenAI API to generate enhanced, personalized astrological interpretations that go beyond static template-based readings.

**Architecture:**
- OpenAI API integration with GPT-4 for interpretation generation
- Prompt engineering system for astrological insights
- Hybrid approach: AI enhances existing interpretations rather than replacing them
- Caching layer to minimize API costs
- Usage tracking and cost management
- Fallback to rule-based interpretations when AI unavailable

**Tech Stack:**
- OpenAI SDK (backend)
- GPT-4 Turbo for interpretation generation
- PostgreSQL for AI cache and usage tracking
- React components for AI-enhanced UI
- Cost monitoring and rate limiting

---

## Task 1: OpenAI API Integration Setup

**Files:**
- Create: `backend/src/modules/ai/config/openai.config.ts`
- Create: `backend/src/modules/ai/services/openai.service.ts`
- Modify: `backend/package.json` (add openai dependency)
- Create: `backend/.env.ai.example` (API key template)

**Step 1: Write the failing test**

Create file: `backend/src/__tests__/ai/openai.service.test.ts`

```typescript
import { describe, it, expect, beforeEach, vi } from 'vitest';
import openaiService from '../../modules/ai/services/openai.service';

// Mock OpenAI
vi.mock('openai', () => ({
  default: vi.fn().mockImplementation(() => ({
    chat: {
      completions: {
        create: vi.fn(),
      },
    },
  })),
}));

describe('OpenAI Service', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should generate interpretation for natal chart', async () => {
    const chartData = {
      planets: [
        { planet: 'sun', sign: 'aries', degree: 15, house: 1 },
        { planet: 'moon', sign: 'taurus', degree: 10, house: 2 },
      ],
    };

    const interpretation = await openaiService.generateNatalInterpretation(chartData);

    expect(interpretation).toBeDefined();
    expect(interpretation).toHaveProperty('sunInAries');
    expect(interpretation).toHaveProperty('moonInTaurus');
  });

  it('should handle API errors gracefully', async () => {
    // Mock API error
    const OpenAI = require('openai');
    const mockOpenAI = new OpenAI();
    mockOpenAI.chat.completions.create.mockRejectedValue(new Error('API Error'));

    const chartData = { planets: [] };

    await expect(
      openaiService.generateNatalInterpretation(chartData)
    ).rejects.toThrow('Failed to generate interpretation');
  });

  it('should use cached interpretations when available', async () => {
    const chartData = {
      planets: [
        { planet: 'sun', sign: 'aries', degree: 15, house: 1 },
      ],
    };

    // First call should hit API
    const result1 = await openaiService.generateNatalInterpretation(chartData);

    // Second call should use cache
    const result2 = await openaiService.generateNatalInterpretation(chartData);

    expect(result1).toEqual(result2);
  });
});
```

**Step 2: Run test to verify it fails**

Run: `cd backend && npm test openai.service.test.ts`
Expected: FAIL with "Cannot find module '../../modules/ai/services/openai.service'"

**Step 3: Install OpenAI SDK**

Run: `cd backend && npm install openai`
Expected: openai added to dependencies

**Step 4: Create OpenAI configuration**

Create file: `backend/src/modules/ai/config/openai.config.ts`

```typescript
/**
 * OpenAI Configuration
 */

export interface OpenAIConfig {
  apiKey: string;
  model: string;
  maxTokens: number;
  temperature: number;
}

export const openaiConfig: OpenAIConfig = {
  apiKey: process.env.OPENAI_API_KEY || '',
  model: process.env.OPENAI_MODEL || 'gpt-4-turbo-preview',
  maxTokens: parseInt(process.env.OPENAI_MAX_TOKENS || '2000'),
  temperature: parseFloat(process.env.OPENAI_TEMPERATURE || '0.7'),
};

export const PROMPT_TEMPLATES = {
  natalChart: `You are an expert astrologer providing personalized natal chart interpretations. Based on the following birth chart data, provide detailed, insightful, and empowering interpretations.

Focus on:
- Core personality traits and potentials
- Emotional nature and needs
- Communication style
- Relationship dynamics
- Career strengths and challenges
- Life purpose and growth opportunities

Use astrological terminology but make it accessible. Be encouraging, specific, and nuanced. Avoid generic platitudes.

Chart Data:
{chartData}

Provide interpretations for each key placement.`,

  transitForecast: `You are an expert astrologer providing transit forecast interpretations. Based on the following current transits affecting the natal chart, provide practical guidance.

Focus on:
- Overall themes and energies
- Specific opportunities and challenges
- Timing considerations
- Actionable advice
- Empowerment and perspective

Current Transits:
{transitData}

Provide a comprehensive forecast interpretation.`,

  compatibility: `You are an expert astrologer providing synastry (compatibility) interpretations. Based on the following two charts, analyze the relationship dynamics.

Focus on:
- Strengths and synergies
- Potential challenges
- Communication styles
- Emotional compatibility
- Long-term potential
- Growth opportunities

Chart A:
{chartA}

Chart B:
{chartB}

Provide a balanced, insightful compatibility analysis.`,
};
```

**Step 5: Implement OpenAI service**

Create file: `backend/src/modules/ai/services/openai.service.ts`

```typescript
/**
 * OpenAI Service
 * Handles AI-powered interpretation generation
 */

import OpenAI from 'openai';
import { openaiConfig, PROMPT_TEMPLATES } from '../config/openai.config';
import logger from '../../../config/logger';

const openai = new OpenAI({
  apiKey: openaiConfig.apiKey,
});

export interface NatalChartInput {
  planets: Array<{
    planet: string;
    sign: string;
    degree: number;
    house: number;
    retrograde?: boolean;
  }>;
  houses?: Array<{
    house: number;
    sign: string;
    degree: number;
  }>;
  aspects?: Array<{
    planet1: string;
    planet2: string;
    type: string;
    orb: number;
  }>;
}

export interface TransitInput {
  currentTransits: Array<{
    planet: string;
    type: string;
    natalPlanet: string;
    orb: number;
    startDate: string;
    endDate: string;
  }>;
}

export interface SynastryInput {
  chartA: NatalChartInput;
  chartB: NatalChartInput;
}

class OpenAIService {
  /**
   * Generate AI-powered natal chart interpretation
   */
  async generateNatalInterpretation(chartData: NatalChartInput): Promise<any> {
    try {
      const prompt = this.formatPrompt(PROMPT_TEMPLATES.natalChart, { chartData: JSON.stringify(chartData, null, 2) });

      const completion = await openai.chat.completions.create({
        model: openaiConfig.model,
        messages: [
          {
            role: 'system',
            content: 'You are an expert astrologer providing accurate, insightful, and empowering interpretations.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        max_tokens: openaiConfig.maxTokens,
        temperature: openaiConfig.temperature,
      });

      const interpretation = this.parseInterpretation(completion.choices[0].message.content || '');

      return interpretation;
    } catch (error: any) {
      logger.error('OpenAI API error:', error);
      throw new Error('Failed to generate interpretation');
    }
  }

  /**
   * Generate AI-powered transit forecast
   */
  async generateTransitForecast(transitData: TransitInput): Promise<any> {
    try {
      const prompt = this.formatPrompt(PROMPT_TEMPLATES.transitForecast, {
        transitData: JSON.stringify(transitData, null, 2),
      });

      const completion = await openai.chat.completions.create({
        model: openaiConfig.model,
        messages: [
          {
            role: 'system',
            content: 'You are an expert astrologer providing accurate transit forecasts.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        max_tokens: openaiConfig.maxTokens,
        temperature: openaiConfig.temperature,
      });

      const interpretation = this.parseInterpretation(completion.choices[0].message.content || '');

      return interpretation;
    } catch (error: any) {
      logger.error('OpenAI API error:', error);
      throw new Error('Failed to generate transit forecast');
    }
  }

  /**
   * Generate AI-powered compatibility analysis
   */
  async generateCompatibilityAnalysis(synastryData: SynastryInput): Promise<any> {
    try {
      const prompt = this.formatPrompt(PROMPT_TEMPLATES.compatibility, {
        chartA: JSON.stringify(synastryData.chartA, null, 2),
        chartB: JSON.stringify(synastryData.chartB, null, 2),
      });

      const completion = await openai.chat.completions.create({
        model: openaiConfig.model,
        messages: [
          {
            role: 'system',
            content: 'You are an expert astrologist providing insightful synastry analyses.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        max_tokens: openaiConfig.maxTokens,
        temperature: openaiConfig.temperature,
      });

      const interpretation = this.parseInterpretation(completion.choices[0].message.content || '');

      return interpretation;
    } catch (error: any) {
      logger.error('OpenAI API error:', error);
      throw new Error('Failed to generate compatibility analysis');
    }
  }

  /**
   * Format prompt with data
   */
  private formatPrompt(template: string, data: Record<string, string>): string {
    let prompt = template;
    for (const [key, value] of Object.entries(data)) {
      prompt = prompt.replace(`{${key}}`, value);
    }
    return prompt;
  }

  /**
   * Parse AI response into structured format
   */
  private parseInterpretation(response: string): any {
    // Try to parse as JSON first
    try {
      return JSON.parse(response);
    } catch {
      // If not JSON, return as text
      return {
        text: response,
        generated: true,
      };
    }
  }

  /**
   * Check if OpenAI is configured
   */
  isConfigured(): boolean {
    return !!openaiConfig.apiKey;
  }

  /**
   * Get usage statistics
   */
  async getUsageStats(): Promise<any> {
    // This would call OpenAI API to get usage/billing info
    // For now, return placeholder
    return {
      available: true,
      usage: {},
    };
  }
}

export default new OpenAIService();
```

**Step 6: Create environment template**

Create file: `backend/.env.ai.example`

```bash
# OpenAI API Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7

# AI Cache Configuration
AI_CACHE_TTL=86400
AI_ENABLE_CACHE=true
```

**Step 7: Run tests to verify they pass**

Run: `cd backend && npm test openai.service.test.ts`
Expected: PASS

**Step 8: Commit**

```bash
git add backend/src/modules/ai backend/package.json backend/.env.ai.example backend/src/__tests__/ai/openai.service.test.ts
git commit -m "feat(ai): add OpenAI API integration service"
```

---

## Task 2: AI Cache Layer

**Files:**
- Create: `backend/migrations/TIMESTAMP_create_ai_cache_table.ts`
- Create: `backend/src/modules/ai/models/aiCache.model.ts`
- Create: `backend/src/modules/ai/services/aiCache.service.ts`
- Create: `backend/src/__tests__/ai/aiCache.service.test.ts`

**Step 1: Write the failing test**

Create file: `backend/src/__tests__/ai/aiCache.service.test.ts`

```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import aiCacheService from '../../modules/ai/services/aiCache.service';

describe('AI Cache Service', () => {
  beforeEach(async () => {
    // Clear cache before each test
    await aiCacheService.clear();
  });

  it('should cache interpretation results', async () => {
    const key = 'natal-chart-123';
    const data = { interpretation: 'Test interpretation' };

    await aiCacheService.set(key, data);
    const cached = await aiCacheService.get(key);

    expect(cached).toEqual(data);
  });

  it('should return null for non-existent keys', async () => {
    const cached = await aiCacheService.get('non-existent');

    expect(cached).toBeNull();
  });

  it('should expire cached entries', async () => {
    const key = 'test-key';
    const data = { test: 'data' };

    await aiCacheService.set(key, data, 1); // 1 second TTL

    // Wait for expiration
    await new Promise(resolve => setTimeout(resolve, 1100));

    const cached = await aiCacheService.get(key);
    expect(cached).toBeNull();
  });

  it('should generate cache key from chart data', async () => {
    const chartData = {
      planets: [
        { planet: 'sun', sign: 'aries', degree: 15 },
      ],
    };

    const key = aiCacheService.generateKey(chartData);

    expect(key).toBeDefined();
    expect(typeof key).toBe('string');
  });
});
```

**Step 2: Run test to verify it fails**

Run: `cd backend && npm test aiCache.service.test.ts`
Expected: FAIL with module not found

**Step 3: Create database migration**

Create file: `backend/migrations/20260216220000_create_ai_cache_table.ts`

```typescript
/**
 * Create AI Cache Table
 */

import type { Knex } from 'knex';

export async function up(knex: Knex): Promise<void> {
  return knex.schema.createTable('ai_cache', (table) => {
    table.uuid('id').primary().defaultTo(knex.raw('gen_random_uuid()'));
    table.text('cache_key').notNullable().unique();
    table.jsonb('data').notNullable();
    table.timestamp('expires_at').nullable();
    table.timestamps(true, true);

    table.index('cache_key');
    table.index('expires_at');
  });
}

export async function down(knex: Knex): Promise<void> {
  return knex.schema.dropTableIfExists('ai_cache');
}
```

**Step 4: Create cache model**

Create file: `backend/src/modules/ai/models/aiCache.model.ts`

```typescript
/**
 * AI Cache Model
 */

import { db } from '../../config/database';

export interface AICacheEntry {
  id: string;
  cacheKey: string;
  data: any;
  expiresAt: Date | null;
  createdAt: Date;
  updatedAt: Date;
}

class AICacheModel {
  async set(cacheKey: string, data: any, ttlSeconds?: number): Promise<AICacheEntry> {
    const expiresAt = ttlSeconds
      ? new Date(Date.now() + ttlSeconds * 1000)
      : null;

    const [entry] = await db<AICacheEntry>('ai_cache')
      .insert({
        cache_key: cacheKey,
        data,
        expires_at: expiresAt,
      })
      .onConflict('cache_key')
      .merge()
      .returning('*');

    return entry;
  }

  async get(cacheKey: string): Promise<any | null> {
    const entry = await db<AICacheEntry>('ai_cache')
      .where('cache_key', cacheKey)
      .where((builder) =>
        builder
          .whereNull('expires_at')
          .orWhere('expires_at', '>', new Date())
      )
      .first();

    return entry?.data || null;
  }

  async delete(cacheKey: string): Promise<boolean> {
    const count = await db('ai_cache')
      .where('cache_key', cacheKey)
      .delete();

    return count > 0;
  }

  async clear(): Promise<void> {
    await db('ai_cache').truncate();
  }

  async clearExpired(): Promise<number> {
    return db('ai_cache')
      .where('expires_at', '<', new Date())
      .delete();
  }
}

export default new AICacheModel();
```

**Step 5: Implement cache service**

Create file: `backend/src/modules/ai/services/aiCache.service.ts`

```typescript
/**
 * AI Cache Service
 * Caches AI-generated interpretations to reduce API costs
 */

import crypto from 'crypto';
import aiCacheModel from '../models/aiCache.model';
import logger from '../../../config/logger';

export interface CacheOptions {
  ttl?: number; // Time to live in seconds
}

class AICacheService {
  /**
   * Get cached interpretation
   */
  async get(key: string): Promise<any | null> {
    try {
      return await aiCacheModel.get(key);
    } catch (error) {
      logger.error('Cache get error:', error);
      return null;
    }
  }

  /**
   * Set cache entry
   */
  async set(key: string, data: any, options?: CacheOptions): Promise<void> {
    try {
      await aiCacheModel.set(key, data, options?.ttl);
    } catch (error) {
      logger.error('Cache set error:', error);
    }
  }

  /**
   * Delete cache entry
   */
  async delete(key: string): Promise<void> {
    try {
      await aiCacheModel.delete(key);
    } catch (error) {
      logger.error('Cache delete error:', error);
    }
  }

  /**
   * Clear all cache
   */
  async clear(): Promise<void> {
    try {
      await aiCacheModel.clear();
    } catch (error) {
      logger.error('Cache clear error:', error);
    }
  }

  /**
   * Clear expired entries
   */
  async clearExpired(): Promise<void> {
    try {
      await aiCacheModel.clearExpired();
    } catch (error) {
      logger.error('Cache clearExpired error:', error);
    }
  }

  /**
   * Generate cache key from data
   */
  generateKey(data: any): string {
    const hash = crypto
      .createHash('sha256')
      .update(JSON.stringify(data))
      .digest('hex');

    return `ai:${hash}`;
  }

  /**
   * Get or generate pattern (cache-aside)
   */
  async getOrGenerate(
    key: string,
    generator: () => Promise<any>,
    options?: CacheOptions
  ): Promise<any> {
    // Try to get from cache
    const cached = await this.get(key);
    if (cached) {
      logger.info('Cache hit:', key);
      return cached;
    }

    // Generate new data
    logger.info('Cache miss, generating:', key);
    const data = await generator();

    // Store in cache
    await this.set(key, data, options);

    return data;
  }
}

export default new AICacheService();
```

**Step 6: Run tests to verify they pass**

Run: `cd backend && npm test aiCache.service.test.ts`
Expected: PASS

**Step 7: Commit**

```bash
git add backend/migrations/20260216220000_create_ai_cache_table.ts backend/src/modules/ai/models/aiCache.model.ts backend/src/modules/ai/services/aiCache.service.ts backend/src/__tests__/ai/aiCache.service.test.ts
git commit -m "feat(ai): add AI cache layer to reduce API costs"
```

---

## Task 3: AI-Enhanced Interpretation Service

**Files:**
- Create: `backend/src/modules/ai/services/aiInterpretation.service.ts`
- Create: `backend/src/__tests__/ai/aiInterpretation.service.test.ts`

**Step 1: Write the failing test**

Create file: `backend/src/__tests__/ai/aiInterpretation.service.test.ts`

```typescript
import { describe, it, expect, beforeEach, vi } from 'vitest';
import aiInterpretationService from '../../modules/ai/services/aiInterpretation.service';

// Mock dependencies
vi.mock('../../modules/ai/services/openai.service', () => ({
  default: {
    generateNatalInterpretation: vi.fn(),
    generateTransitForecast: vi.fn(),
    generateCompatibilityAnalysis: vi.fn(),
    isConfigured: vi.fn(() => true),
  },
}));

vi.mock('../../modules/ai/services/aiCache.service', () => ({
  default: {
    getOrGenerate: vi.fn(),
  },
}));

import openaiService from '../../modules/ai/services/openai.service';
import aiCacheService from '../../modules/ai/services/aiCache.service';

describe('AI Interpretation Service', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should generate enhanced natal interpretation', async () => {
    const chartData = {
      planets: [
        { planet: 'sun', sign: 'aries', degree: 15, house: 1 },
      ],
    };

    (aiCacheService.getOrGenerate as any).mockResolvedValue({
      enhanced: 'AI-enhanced interpretation',
      confidence: 0.9,
    });

    const result = await aiInterpretationService.generateNatal(chartData);

    expect(result).toHaveProperty('enhanced');
    expect(result).toHaveProperty('confidence');
    expect(aiCacheService.getOrGenerate).toHaveBeenCalled();
  });

  it('should fallback to rule-based when AI unavailable', async () => {
    (openaiService.isConfigured as any).mockReturnValue(false);

    const chartData = { planets: [] };

    const result = await aiInterpretationService.generateNatal(chartData);

    expect(result).toHaveProperty('interpretation');
    expect(result.ai).toBe(false);
  });

  it('should generate enhanced transit forecast', async () => {
    const transitData = {
      currentTransits: [
        { planet: 'jupiter', type: 'trine', natalPlanet: 'sun' },
      ],
    };

    (aiCacheService.getOrGenerate as any).mockResolvedValue({
      forecast: 'AI-enhanced forecast',
      keyDates: ['2026-03-15'],
    });

    const result = await aiInterpretationService.generateTransit(transitData);

    expect(result).toHaveProperty('forecast');
    expect(result).toHaveProperty('keyDates');
  });

  it('should generate enhanced compatibility analysis', async () => {
    const synastryData = {
      chartA: { planets: [] },
      chartB: { planets: [] },
    };

    (aiCacheService.getOrGenerate as any).mockResolvedValue({
      compatibility: 85,
      insights: ['Strong emotional connection'],
    });

    const result = await aiInterpretationService.generateCompatibility(synastryData);

    expect(result).toHaveProperty('compatibility');
    expect(result).toHaveProperty('insights');
    expect(Array.isArray(result.insights)).toBe(true);
  });
});
```

**Step 2: Run test to verify it fails**

Run: `cd backend && npm test aiInterpretation.service.test.ts`
Expected: FAIL with module not found

**Step 3: Implement AI interpretation service**

Create file: `backend/src/modules/ai/services/aiInterpretation.service.ts`

```typescript
/**
 * AI-Enhanced Interpretation Service
 * Combines rule-based interpretations with AI enhancement
 */

import openaiService from './openai.service';
import aiCacheService from './aiCache.service';
import { generateCompletePersonalityAnalysis } from '../../analysis/services/interpretation.service';
import logger from '../../../config/logger';

export interface ChartData {
  planets: any[];
  houses?: any[];
  aspects?: any[];
}

export interface TransitData {
  currentTransits: any[];
}

export interface SynastryData {
  chartA: ChartData;
  chartB: ChartData;
}

class AIInterpretationService {
  /**
   * Generate AI-enhanced natal chart interpretation
   */
  async generateNatal(chartData: ChartData): Promise<any> {
    // Check if AI is configured
    if (!openaiService.isConfigured()) {
      // Fallback to rule-based
      const ruleBased = generateCompletePersonalityAnalysis(chartData);
      return {
        ...ruleBased,
        ai: false,
        source: 'rule-based',
      };
    }

    try {
      const cacheKey = aiCacheService.generateKey({ type: 'natal', chartData });

      // Generate with AI
      const result = await aiCacheService.getOrGenerate(
        cacheKey,
        async () => {
          const aiInterpretation = await openaiService.generateNatalInterpretation(chartData);

          // Combine with rule-based for comprehensive reading
          const ruleBased = generateCompletePersonalityAnalysis(chartData);

          return {
            ...ruleBased,
            ai: true,
            enhanced: aiInterpretation,
            source: 'ai-enhanced',
            generatedAt: new Date().toISOString(),
          };
        },
        { ttl: 86400 } // Cache for 24 hours
      );

      return result;
    } catch (error: any) {
      logger.error('AI interpretation failed, falling back to rule-based:', error);

      // Fallback to rule-based
      const ruleBased = generateCompletePersonalityAnalysis(chartData);
      return {
        ...ruleBased,
        ai: false,
        source: 'rule-based',
      };
    }
  }

  /**
   * Generate AI-enhanced transit forecast
   */
  async generateTransit(transitData: TransitData): Promise<any> {
    if (!openaiService.isConfigured()) {
      return {
        forecast: 'Transit forecast not available',
        ai: false,
        source: 'rule-based',
      };
    }

    try {
      const cacheKey = aiCacheService.generateKey({ type: 'transit', transitData });

      const result = await aiCacheService.getOrGenerate(
        cacheKey,
        async () => {
          const aiForecast = await openaiService.generateTransitForecast(transitData);

          return {
            forecast: aiForecast,
            ai: true,
            source: 'ai-enhanced',
            generatedAt: new Date().toISOString(),
          };
        },
        { ttl: 3600 } // Cache for 1 hour (transits change)
      );

      return result;
    } catch (error: any) {
      logger.error('AI transit forecast failed:', error);
      return {
        forecast: 'Transit forecast unavailable',
        ai: false,
        source: 'rule-based',
      };
    }
  }

  /**
   * Generate AI-enhanced compatibility analysis
   */
  async generateCompatibility(synastryData: SynastryData): Promise<any> {
    if (!openaiService.isConfigured()) {
      return {
        compatibility: 50,
        analysis: 'Compatibility analysis unavailable',
        ai: false,
      };
    }

    try {
      const cacheKey = aiCacheService.generateKey({ type: 'synastry', synastryData });

      const result = await aiCacheService.getOrGenerate(
        cacheKey,
        async () => {
          const aiAnalysis = await openaiService.generateCompatibilityAnalysis(synastryData);

          return {
            ...aiAnalysis,
            ai: true,
            source: 'ai-enhanced',
            generatedAt: new Date().toISOString(),
          };
        },
        { ttl: 86400 } // Cache for 24 hours
      );

      return result;
    } catch (error: any) {
      logger.error('AI compatibility analysis failed:', error);
      return {
        compatibility: 50,
        analysis: 'Compatibility analysis unavailable',
        ai: false,
      };
    }
  }

  /**
   * Batch generate interpretations for multiple charts
   */
  async batchGenerateNatal(charts: ChartData[]): Promise<any[]> {
    const results = await Promise.allSettled(
      charts.map(chart => this.generateNatal(chart))
    );

    return results.map((result, index) => ({
      chartIndex: index,
      success: result.status === 'fulfilled',
      data: result.status === 'fulfilled' ? result.value : null,
      error: result.status === 'rejected' ? result.reason : null,
    }));
  }
}

export default new AIInterpretationService();
```

**Step 4: Run tests to verify they pass**

Run: `cd backend && npm test aiInterpretation.service.test.ts`
Expected: PASS

**Step 5: Commit**

```bash
git add backend/src/modules/ai/services/aiInterpretation.service.ts backend/src/__tests__/ai/aiInterpretation.service.test.ts
git commit -m "feat(ai): add AI-enhanced interpretation service with fallback"
```

---

## Task 4: AI API Endpoints

**Files:**
- Create: `backend/src/modules/ai/controllers/ai.controller.ts`
- Create: `backend/src/modules/ai/routes/ai.routes.ts`
- Create: `backend/src/modules/ai/index.ts`
- Create: `backend/src/__tests__/ai/ai.controller.test.ts`

**Step 1: Write the failing test**

Create file: `backend/src/__tests__/ai/ai.controller.test.ts`

```typescript
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import request from 'supertest';
import app from '../../server';
import { TestDataSource } from '../config/database.test';

describe('AI API Endpoints', () => {
  let authToken: string;

  beforeAll(async () => {
    await TestDataSource.initialize();
    await TestDataSource.migrate();

    const registerResponse = await request(app)
      .post('/api/v1/auth/register')
      .send({
        email: 'ai@test.com',
        password: 'Password123!',
        firstName: 'Test',
        lastName: 'User',
      });

    authToken = registerResponse.body.data.token;
  });

  afterAll(async () => {
    await TestDataSource.cleanup();
  });

  it('should generate AI natal interpretation', async () => {
    const response = await request(app)
      .post('/api/v1/ai/natal')
      .set('Authorization', `Bearer ${authToken}`)
      .send({
        planets: [
          { planet: 'sun', sign: 'aries', degree: 15, house: 1 },
        ],
      });

    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
    expect(response.body.data).toHaveProperty('interpretation');
  });

  it('should return 503 if AI not configured', async () => {
    // Mock AI not configured
    const originalKey = process.env.OPENAI_API_KEY;
    delete process.env.OPENAI_API_KEY;

    const response = await request(app)
      .post('/api/v1/ai/natal')
      .set('Authorization', `Bearer ${authToken}`)
      .send({ planets: [] });

    expect(response.status).toBe(200); // Should fallback to rule-based
    expect(response.body.data.ai).toBe(false);

    process.env.OPENAI_API_KEY = originalKey;
  });

  it('should generate AI transit forecast', async () => {
    const response = await request(app)
      .post('/api/v1/ai/transit')
      .set('Authorization', `Bearer ${authToken}`)
      .send({
        currentTransits: [],
      });

    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
  });

  it('should generate AI compatibility analysis', async () => {
    const response = await request(app)
      .post('/api/v1/ai/compatibility')
      .set('Authorization', `Bearer ${authToken}`)
      .send({
        chartA: { planets: [] },
        chartB: { planets: [] },
      });

    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
  });
});
```

**Step 2: Run test to verify it fails**

Run: `cd backend && npm test ai.controller.test.ts`
Expected: FAIL with module not found

**Step 3: Create AI controller**

Create file: `backend/src/modules/ai/controllers/ai.controller.ts`

```typescript
/**
 * AI Controller
 * Handles AI-powered interpretation requests
 */

import asyncHandler from '../../../utils/asyncHandler';
import aiInterpretationService from '../services/aiInterpretation.service';
import { Request, Response } from 'express';
import openaiService from '../services/openai.service';

export const generateNatal = asyncHandler(async (req: Request, res: Response) => {
  const chartData = req.body;

  const interpretation = await aiInterpretationService.generateNatal(chartData);

  res.json({
    success: true,
    data: interpretation,
  });
});

export const generateTransit = asyncHandler(async (req: Request, res: Response) => {
  const transitData = req.body;

  const forecast = await aiInterpretationService.generateTransit(transitData);

  res.json({
    success: true,
    data: forecast,
  });
});

export const generateCompatibility = asyncHandler(async (req: Request, res: Response) => {
  const { chartA, chartB } = req.body;

  const analysis = await aiInterpretationService.generateCompatibility({ chartA, chartB });

  res.json({
    success: true,
    data: analysis,
  });
});

export const checkStatus = asyncHandler(async (req: Request, res: Response) => {
  const configured = openaiService.isConfigured();

  res.json({
    success: true,
    data: {
      available: configured,
      service: configured ? 'openai' : null,
    },
  });
});

export const getUsageStats = asyncHandler(async (req: Request, res: Response) => {
  const stats = await openaiService.getUsageStats();

  res.json({
    success: true,
    data: stats,
  });
});
```

**Step 4: Create AI routes**

Create file: `backend/src/modules/ai/routes/ai.routes.ts`

```typescript
/**
 * AI Routes
 */

import express from 'express';
import {
  generateNatal,
  generateTransit,
  generateCompatibility,
  checkStatus,
  getUsageStats,
} from '../controllers/ai.controller';
import { authenticate } from '../../../middleware/auth';

const router = express.Router();

// Public endpoints
router.get('/status', checkStatus);

// Authenticated endpoints
router.use(authenticate);

router.post('/natal', generateNatal);
router.post('/transit', generateTransit);
router.post('/compatibility', generateCompatibility);
router.get('/usage', getUsageStats);

export default router;
```

**Step 5: Create module index**

Create file: `backend/src/modules/ai/index.ts`

```typescript
/**
 * AI Module
 * Exports all AI-related functionality
 */

export { default as openaiService } from './services/openai.service';
export { default as aiCacheService } from './services/aiCache.service';
export { default as aiInterpretationService } from './services/aiInterpretation.service';
```

**Step 6: Register routes in API**

Modify: `backend/src/api/v1/index.ts`

Add:
```typescript
import aiRoutes from '../../modules/ai/routes/ai.routes';

router.use('/ai', aiRoutes);
```

**Step 7: Run tests to verify they pass**

Run: `cd backend && npm test ai.controller.test.ts`
Expected: PASS

**Step 8: Commit**

```bash
git add backend/src/modules/ai backend/src/api/v1/index.ts backend/src/__tests__/ai/ai.controller.test.ts
git commit -m "feat(ai): add AI API endpoints for interpretation generation"
```

---

## Task 5: Frontend AI Integration

**Files:**
- Create: `frontend/src/services/ai.service.ts`
- Create: `frontend/src/hooks/useAIInterpretation.ts`
- Create: `frontend/src/components/AIInterpretationToggle.tsx`
- Create: `frontend/src/styles/AIInterpretationToggle.css`
- Create: `frontend/src/__tests__/hooks/useAIInterpretation.test.tsx`

**Step 1: Write the failing test**

Create file: `frontend/src/__tests__/hooks/useAIInterpretation.test.tsx`

```typescript
import { describe, it, expect, vi } from 'vitest';
import { renderHook, waitFor } from '@testing-library/react';
import { useAIInterpretation } from '../hooks/useAIInterpretation';

// Mock axios
vi.mock('axios', () => ({
  default: {
    post: vi.fn(),
  },
}));

import axios from 'axios';

describe('useAIInterpretation Hook', () => {
  it('should generate AI natal interpretation', async () => {
    const mockAIResponse = {
      data: {
        success: true,
        data: {
          enhanced: 'AI interpretation',
          ai: true,
        },
      },
    };

    (axios.post as any).mockResolvedValue(mockAIResponse);

    const { result } = renderHook(() => useAIInterpretation());

    const interpretation = await result.current.generateNatal({
      planets: [
        { planet: 'sun', sign: 'aries', degree: 15, house: 1 },
      ],
    });

    await waitFor(() => {
      expect(interpretation).toHaveProperty('enhanced');
      expect(interpretation.ai).toBe(true);
    });
  });

  it('should handle AI unavailable gracefully', async () => {
    const mockResponse = {
      data: {
        success: true,
        data: {
          interpretation: 'Rule-based interpretation',
          ai: false,
        },
      },
    };

    (axios.post as any).mockResolvedValue(mockResponse);

    const { result } = renderHook(() => useAIInterpretation());

    const interpretation = await result.current.generateNatal({ planets: [] });

    await waitFor(() => {
      expect(interpretation.ai).toBe(false);
    });
  });
});
```

**Step 2: Run test to verify it fails**

Run: `cd frontend && npm test useAIInterpretation.test.tsx`
Expected: FAIL with module not found

**Step 3: Create AI service**

Create file: `frontend/src/services/ai.service.ts`

```typescript
/**
 * AI Service
 * Handles AI-powered interpretation API calls
 */

import api from './api';

export interface AIInterpretationResponse {
  interpretation: any;
  enhanced?: string;
  ai: boolean;
  source: string;
  generatedAt?: string;
}

class AIService {
  /**
   * Generate AI natal interpretation
   */
  async generateNatal(chartData: any): Promise<AIInterpretationResponse> {
    const response = await api.post('/ai/natal', chartData);
    return response.data.data;
  }

  /**
   * Generate AI transit forecast
   */
  async generateTransit(transitData: any): Promise<AIInterpretationResponse> {
    const response = await api.post('/ai/transit', transitData);
    return response.data.data;
  }

  /**
   * Generate AI compatibility analysis
   */
  async generateCompatibility(synastryData: {
    chartA: any;
    chartB: any;
  }): Promise<AIInterpretationResponse> {
    const response = await api.post('/ai/compatibility', synastryData);
    return response.data.data;
  }

  /**
   * Check AI service status
   */
  async checkStatus(): Promise<{ available: boolean; service: string | null }> {
    const response = await api.get('/ai/status');
    return response.data.data;
  }

  /**
   * Get usage statistics
   */
  async getUsageStats(): Promise<any> {
    const response = await api.get('/ai/usage');
    return response.data.data;
  }
}

export default new AIService();
```

**Step 4: Create AI interpretation hook**

Create file: `frontend/src/hooks/useAIInterpretation.ts`

```typescript
/**
 * AI Interpretation Hook
 * Manages AI-powered interpretation generation
 */

import { useState } from 'react';
import { useMutation, useQuery } from '@tanstack/react-query';
import aiService from '../services/ai.service';

interface UseAIInterpretationResult {
  generateNatal: (chartData: any) => Promise<any>;
  generateTransit: (transitData: any) => Promise<any>;
  generateCompatibility: (synastryData: any) => Promise<any>;
  isGenerating: boolean;
  error: Error | null;
  isAvailable: boolean;
}

export function useAIInterpretation(): UseAIInterpretationResult {
  const [error, setError] = useState<Error | null>(null);

  // Check AI availability
  const { data: status } = useQuery({
    queryKey: ['ai-status'],
    queryFn: () => aiService.checkStatus(),
    retry: false,
  });

  const natalMutation = useMutation({
    mutationFn: (chartData: any) => aiService.generateNatal(chartData),
    onError: (err) => setError(err as Error),
  });

  const transitMutation = useMutation({
    mutationFn: (transitData: any) => aiService.generateTransit(transitData),
    onError: (err) => setError(err as Error),
  });

  const compatibilityMutation = useMutation({
    mutationFn: (synastryData: any) => aiService.generateCompatibility(synastryData),
    onError: (err) => setError(err as Error),
  });

  return {
    generateNatal: natalMutation.mutateAsync,
    generateTransit: transitMutation.mutateAsync,
    generateCompatibility: compatibilityMutation.mutateAsync,
    isGenerating: natalMutation.isPending,
    error,
    isAvailable: status?.available || false,
  };
}
```

**Step 5: Create AI toggle component**

Create file: `frontend/src/components/AIInterpretationToggle.tsx`

```typescript
/**
 * AI Interpretation Toggle Component
 * Allows users to enable/disable AI enhancements
 */

import React, { useState } from 'react';
import { useAIInterpretation } from '../hooks/useAIInterpretation';
import { Sparkles, Info } from 'lucide-react';
import './AIInterpretationToggle.css';

interface AIInterpretationToggleProps {
  onInterpretationGenerated?: (interpretation: any) => void;
}

export const AIInterpretationToggle: React.FC<AIInterpretationToggleProps> = ({
  onInterpretationGenerated,
}) => {
  const { isAvailable, generateNatal, isGenerating, error } = useAIInterpretation();
  const [enabled, setEnabled] = useState(false);
  const [showInfo, setShowInfo] = useState(false);

  if (!isAvailable) {
    return null;
  }

  const handleGenerate = async (chartData: any) => {
    if (!enabled) return;

    try {
      const interpretation = await generateNatal(chartData);

      if (onInterpretationGenerated) {
        onInterpretationGenerated(interpretation);
      }
    } catch (err) {
      console.error('AI generation failed:', err);
    }
  };

  return (
    <div className="ai-toggle-container">
      <div className="ai-toggle-header">
        <div className="ai-toggle-title">
          <Sparkles className="ai-icon" size={18} />
          <span>AI-Enhanced Interpretations</span>
        </div>
        <button
          className="ai-info-button"
          onClick={() => setShowInfo(!showInfo)}
        >
          <Info size={16} />
        </button>
      </div>

      {showInfo && (
        <div className="ai-toggle-info">
          <p>
            Enable AI to generate personalized, nuanced interpretations powered by GPT-4.
            AI enhances the rule-based readings with deeper insights and specific guidance.
          </p>
          <p className="ai-note">
            <small>Note: AI interpretations take longer to generate and use API credits.</small>
          </p>
        </div>
      )}

      <div className="ai-toggle-controls">
        <label className="ai-toggle-switch">
          <input
            type="checkbox"
            checked={enabled}
            onChange={(e) => setEnabled(e.target.checked)}
            disabled={isGenerating}
          />
          <span className="ai-toggle-slider"></span>
        </label>
        <span className="ai-toggle-status">
          {enabled ? 'Enabled' : 'Disabled'}
        </span>
      </div>

      {error && (
        <div className="ai-toggle-error">
          Failed to generate AI interpretation. Using rule-based instead.
        </div>
      )}

      {isGenerating && (
        <div className="ai-toggle-loading">
          <div className="ai-spinner"></div>
          <span>Generating AI interpretation...</span>
        </div>
      )}

      {enabled && (
        <div className="ai-toggle-usage">
          <small>API credits will be used</small>
        </div>
      )}
    </div>
  );
};
```

**Step 6: Add styling**

Create file: `frontend/src/styles/AIInterpretationToggle.css`

```css
/**
 * AI Interpretation Toggle Styles
 */

.ai-toggle-container {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  border-radius: 12px;
  padding: 20px;
  color: white;
  margin-bottom: 20px;
}

.ai-toggle-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 12px;
}

.ai-toggle-title {
  display: flex;
  align-items: center;
  gap: 8px;
  font-weight: 600;
  font-size: 16px;
}

.ai-icon {
  animation: sparkle 2s ease-in-out infinite;
}

@keyframes sparkle {
  0%, 100% { opacity: 1; transform: scale(1); }
  50% { opacity: 0.7; transform: scale(1.1); }
}

.ai-info-button {
  background: rgba(255, 255, 255, 0.2);
  border: none;
  border-radius: 6px;
  padding: 4px 8px;
  color: white;
  cursor: pointer;
  transition: background 0.2s;
}

.ai-info-button:hover {
  background: rgba(255, 255, 255, 0.3);
}

.ai-toggle-info {
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 12px;
  margin-bottom: 12px;
  font-size: 14px;
  line-height: 1.5;
}

.ai-toggle-info p {
  margin: 0 0 8px 0;
}

.ai-toggle-info p:last-child {
  margin: 0;
}

.ai-note {
  opacity: 0.9;
  font-style: italic;
}

.ai-toggle-controls {
  display: flex;
  align-items: center;
  gap: 12px;
}

.ai-toggle-switch {
  position: relative;
  display: inline-block;
  width: 48px;
  height: 24px;
}

.ai-toggle-switch input {
  opacity: 0;
  width: 0;
  height: 0;
}

.ai-toggle-slider {
  position: absolute;
  cursor: pointer;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(255, 255, 255, 0.3);
  transition: 0.3s;
  border-radius: 24px;
}

.ai-toggle-slider:before {
  position: absolute;
  content: '';
  height: 18px;
  width: 18px;
  left: 3px;
  bottom: 3px;
  background-color: white;
  transition: 0.3s;
  border-radius: 50%;
}

.ai-toggle-switch input:checked + .ai-toggle-slider {
  background-color: rgba(255, 255, 255, 0.5);
}

.ai-toggle-switch input:checked + .ai-toggle-slider:before {
  transform: translateX(24px);
}

.ai-toggle-switch input:disabled + .ai-toggle-slider {
  opacity: 0.5;
  cursor: not-allowed;
}

.ai-toggle-status {
  font-size: 14px;
  font-weight: 500;
}

.ai-toggle-error {
  background: rgba(239, 68, 68, 0.2);
  border: 1px solid rgba(239, 68, 68, 0.5);
  border-radius: 6px;
  padding: 8px 12px;
  margin-top: 12px;
  font-size: 13px;
}

.ai-toggle-loading {
  display: flex;
  align-items: center;
  gap: 10px;
  margin-top: 12px;
  font-size: 14px;
}

.ai-spinner {
  width: 18px;
  height: 18px;
  border: 2px solid rgba(255, 255, 255, 0.3);
  border-top: 2px solid white;
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

@keyframes spin {
  0% { transform: rotate(0deg); }
  100% { transform: rotate(360deg); }
}

.ai-toggle-usage {
  margin-top: 12px;
  opacity: 0.8;
}
```

**Step 7: Run tests to verify they pass**

Run: `cd frontend && npm test useAIInterpretation.test.tsx`
Expected: PASS

**Step 8: Commit**

```bash
git add frontend/src/services/ai.service.ts frontend/src/hooks/useAIInterpretation.ts frontend/src/components/AIInterpretationToggle.tsx frontend/src/styles/AIInterpretationToggle.css frontend/src/__tests__/hooks/useAIInterpretation.test.tsx
git commit -m "feat(ai): add frontend AI integration components"
```

---

## Task 6: Usage Tracking and Cost Management

**Files:**
- Create: `backend/migrations/TIMESTAMP_create_ai_usage_table.ts`
- Create: `backend/src/modules/ai/models/aiUsage.model.ts`
- Create: `backend/src/modules/ai/services/aiUsage.service.ts`
- Create: `backend/src/modules/ai/controllers/aiUsage.controller.ts`
- Create: `backend/src/modules/ai/routes/aiUsage.routes.ts`

**Step 1: Create usage tracking migration**

Create file: `backend/migrations/20260216230000_create_ai_usage_table.ts`

```typescript
/**
 * Create AI Usage Tracking Table
 */

import type { Knex } from 'knex';

export async function up(knex: Knex): Promise<void> {
  return knex.schema.createTable('ai_usage', (table) => {
    table.uuid('id').primary().defaultTo(knex.raw('gen_random_uuid()'));
    table.uuid('user_id').notNullable().references('id').inTable('users').onDelete('CASCADE');
    table.string('type').notNullable(); // 'natal', 'transit', 'compatibility'
    table.integer('tokens_used').defaultTo(0);
    table.decimal('cost', 10, 4).defaultTo(0);
    table.jsonb('metadata').nullable();
    table.timestamp('created_at').defaultTo(knex.fn.now());

    table.index('user_id');
    table.index('type');
    table.index('created_at');
  });
}

export async function down(knex: Knex): Promise<void> {
  return knex.schema.dropTableIfExists('ai_usage');
}
```

**Step 2: Create usage model**

Create file: `backend/src/modules/ai/models/aiUsage.model.ts`

```typescript
/**
 * AI Usage Model
 */

import { db } from '../../config/database';

export interface AIUsage {
  id: string;
  userId: string;
  type: 'natal' | 'transit' | 'compatibility';
  tokensUsed: number;
  cost: number;
  metadata?: any;
  createdAt: Date;
}

class AIUsageModel {
  async record(data: {
    userId: string;
    type: string;
    tokensUsed: number;
    cost: number;
    metadata?: any;
  }): Promise<AIUsage> {
    const [usage] = await db<AIUsage>('ai_usage')
      .insert({
        user_id: data.userId,
        type: data.type,
        tokens_used: data.tokensUsed,
        cost: data.cost,
        metadata: data.metadata,
      })
      .returning('*');

    return usage;
  }

  async getByUserId(userId: string, limit = 100): Promise<AIUsage[]> {
    return db<AIUsage>('ai_usage')
      .where('user_id', userId)
      .orderBy('created_at', 'desc')
      .limit(limit)
      .select('*');
  }

  async getTotalCost(userId: string, startDate?: Date): Promise<number> {
    let query = db<AIUsage>('ai_usage')
      .where('user_id', userId);

    if (startDate) {
      query = query.where('created_at', '>=', startDate);
    }

    const result = await query.sum('cost as total').first();
    return parseFloat((result?.total || 0).toString());
  }

  async getTotalTokens(userId: string): Promise<number> {
    const result = await db<AIUsage>('ai_usage')
      .where('user_id', userId)
      .sum('tokens_used as total')
      .first();

    return (result?.total || 0) as number;
  }

  async getUsageByType(userId: string): Promise<Record<string, number>> {
    const results = await db<AIUsage>('ai_usage')
      .where('user_id', userId)
      .select('type')
      .count('* as count')
      .groupBy('type');

    return results.reduce((acc, row: any) => {
      acc[row.type] = parseInt(row.count);
      return acc;
    }, {} as Record<string, number>);
  }
}

export default new AIUsageModel();
```

**Step 3: Implement usage service**

Create file: `backend/src/modules/ai/services/aiUsage.service.ts`

```typescript
/**
 * AI Usage Tracking Service
 */

import aiUsageModel from '../models/aiUsage.model';
import logger from '../../../config/logger';

// Approximate OpenAI pricing (GPT-4 Turbo)
const PRICING = {
  'gpt-4-turbo-preview': {
    input: 0.01 / 1000, // $0.01 per 1K tokens
    output: 0.03 / 1000, // $0.03 per 1K tokens
  },
};

class AIUsageService {
  /**
   * Record AI usage
   */
  async record(data: {
    userId: string;
    type: string;
    inputTokens: number;
    outputTokens: number;
    metadata?: any;
  }): Promise<void> {
    const model = process.env.OPENAI_MODEL || 'gpt-4-turbo-preview';
    const pricing = PRICING[model as keyof typeof PRICING] || PRICING['gpt-4-turbo-preview'];

    const inputCost = data.inputTokens * pricing.input;
    const outputCost = data.outputTokens * pricing.output;
    const totalCost = inputCost + outputCost;
    const totalTokens = data.inputTokens + data.outputTokens;

    await aiUsageModel.record({
      userId: data.userId,
      type: data.type,
      tokensUsed: totalTokens,
      cost: totalCost,
      metadata: {
        ...data.metadata,
        inputTokens: data.inputTokens,
        outputTokens: data.outputTokens,
        model,
      },
    });
  }

  /**
   * Get user usage statistics
   */
  async getUserStats(userId: string): Promise<{
    totalCost: number;
    totalTokens: number;
    byType: Record<string, number>;
    recent: any[];
  }> {
    const totalCost = await aiUsageModel.getTotalCost(userId);
    const totalTokens = await aiUsageModel.getTotalTokens(userId);
    const byType = await aiUsageModel.getUsageByType(userId);
    const recent = await aiUsageModel.getByUserId(userId, 10);

    return {
      totalCost,
      totalTokens,
      byType,
      recent,
    };
  }

  /**
   * Check if user has exceeded usage limits
   */
  async checkLimit(userId: string, limit: number): Promise<boolean> {
    const totalCost = await aiUsageModel.getTotalCost(userId);
    return totalCost < limit;
  }
}

export default new AIUsageService();
```

**Step 4: Update OpenAI service to track usage**

Modify: `backend/src/modules/ai/services/openai.service.ts`

Add to class:
```typescript
import aiUsageService from './aiUsage.service';

// After successful API call, track usage:
await aiUsageService.record({
  userId: currentUserId,
  type: 'natal',
  inputTokens: completion.usage?.prompt_tokens || 0,
  outputTokens: completion.usage?.completion_tokens || 0,
  metadata: { model: openaiConfig.model },
});
```

**Step 5: Create usage controller**

Create file: `backend/src/modules/ai/controllers/aiUsage.controller.ts`

```typescript
/**
 * AI Usage Controller
 */

import asyncHandler from '../../../utils/asyncHandler';
import aiUsageService from '../services/aiUsage.service';
import { Request, Response } from 'express';

export const getUserStats = asyncHandler(async (req: Request, res: Response) => {
  const userId = req.user!.id;

  const stats = await aiUsageService.getUserStats(userId);

  res.json({
    success: true,
    data: stats,
  });
});

export const getUsageHistory = asyncHandler(async (req: Request, res: Response) => {
  const userId = req.user!.id;
  const { limit = 50 } = req.query;

  const history = await aiUsageService.getByUserId(userId, Number(limit));

  res.json({
    success: true,
    data: history,
  });
});
```

**Step 6: Update AI routes**

Modify: `backend/src/modules/ai/routes/ai.routes.ts`

Add:
```typescript
import {
  // existing imports
  getUserStats,
  getUsageHistory,
} from '../controllers/aiUsage.controller';

// Add routes:
router.get('/usage/stats', getUserStats);
router.get('/usage/history', getUsageHistory);
```

**Step 7: Commit**

```bash
git add backend/migrations/20260216230000_create_ai_usage_table.ts backend/src/modules/ai/models/aiUsage.model.ts backend/src/modules/ai/services/aiUsage.service.ts backend/src/modules/ai/controllers/aiUsage.controller.ts backend/src/modules/ai/routes/ai.routes.ts
git commit -m "feat(ai): add usage tracking and cost management"
```

---

## Task 7: AI Interpretation UI Enhancement

**Files:**
- Create: `frontend/src/components/AIInterpretationDisplay.tsx`
- Create: `frontend/src/styles/AIInterpretationDisplay.css`
- Update: `frontend/src/pages/AnalysisPage.tsx` (integrate AI)

**Step 1: Create AI interpretation display component**

Create file: `frontend/src/components/AIInterpretationDisplay.tsx`

```typescript
/**
 * AI Interpretation Display Component
 * Shows AI-enhanced interpretations with special formatting
 */

import React from 'react';
import { Sparkles, AlertCircle } from 'lucide-react';
import './AIInterpretationDisplay.css';

interface AIInterpretationDisplayProps {
  interpretation: any;
}

export const AIInterpretationDisplay: React.FC<AIInterpretationDisplayProps> = ({
  interpretation,
}) => {
  if (!interpretation || !interpretation.ai) {
    return null;
  }

  return (
    <div className="ai-interpretation-display">
      <div className="ai-header">
        <div className="ai-badge">
          <Sparkles size={16} />
          <span>AI-Enhanced</span>
        </div>
        {interpretation.generatedAt && (
          <span className="ai-timestamp">
            Generated {new Date(interpretation.generatedAt).toLocaleString()}
          </span>
        )}
      </div>

      {interpretation.enhanced && (
        <div className="ai-content">
          {typeof interpretation.enhanced === 'string' ? (
            <p className="ai-text">{interpretation.enhanced}</p>
          ) : (
            <div className="ai-structured">
              {Object.entries(interpretation.enhanced).map(([key, value]) => (
                <div key={key} className="ai-section">
                  <h4 className="ai-section-title">{key}</h4>
                  <div className="ai-section-content">
                    {typeof value === 'string' ? (
                      <p>{value}</p>
                    ) : Array.isArray(value) ? (
                      <ul>
                        {value.map((item, i) => (
                          <li key={i}>{item as string}</li>
                        ))}
                      </ul>
                    ) : (
                      <pre>{JSON.stringify(value, null, 2)}</pre>
                    )}
                  </div>
                </div>
              ))}
            </div>
          )}
        </div>
      )}

      <div className="ai-footer">
        <AlertCircle size={14} />
        <small>
          AI interpretations are generated using GPT-4 and may vary. Use as guidance alongside traditional astrological wisdom.
        </small>
      </div>
    </div>
  );
};
```

**Step 2: Add styling**

Create file: `frontend/src/styles/AIInterpretationDisplay.css`

```css
/**
 * AI Interpretation Display Styles
 */

.ai-interpretation-display {
  background: linear-gradient(135deg, #f5f7fa 0%, #e4e8f0 100%);
  border-radius: 12px;
  padding: 24px;
  margin: 20px 0;
  border-left: 4px solid #667eea;
}

.ai-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 16px;
  flex-wrap: wrap;
  gap: 8px;
}

.ai-badge {
  display: flex;
  align-items: center;
  gap: 6px;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 6px 12px;
  border-radius: 20px;
  font-size: 13px;
  font-weight: 600;
}

.ai-timestamp {
  color: #6b7280;
  font-size: 12px;
}

.ai-content {
  margin-bottom: 16px;
}

.ai-text {
  font-size: 15px;
  line-height: 1.7;
  color: #1f2937;
  margin: 0;
  white-space: pre-wrap;
}

.ai-structured {
  display: flex;
  flex-direction: column;
  gap: 16px;
}

.ai-section {
  background: white;
  border-radius: 8px;
  padding: 16px;
  border: 1px solid #e5e7eb;
}

.ai-section-title {
  margin: 0 0 8px 0;
  font-size: 16px;
  font-weight: 600;
  color: #374151;
  text-transform: capitalize;
}

.ai-section-content {
  font-size: 14px;
  line-height: 1.6;
  color: #4b5563;
}

.ai-section-content ul {
  margin: 0;
  padding-left: 20px;
}

.ai-section-content li {
  margin-bottom: 4px;
}

.ai-footer {
  display: flex;
  align-items: flex-start;
  gap: 8px;
  padding-top: 12px;
  border-top: 1px solid #d1d5db;
  color: #6b7280;
  font-size: 12px;
}

.ai-footer small {
  line-height: 1.4;
}
```

**Step 3: Update exports**

Modify: `frontend/src/components/index.ts`

Add:
```typescript
export { AIInterpretationToggle } from './AIInterpretationToggle';
export { AIInterpretationDisplay } from './AIInterpretationDisplay';
```

**Step 4: Integrate into AnalysisPage**

Modify: `frontend/src/pages/AnalysisPage.tsx`

Add AI integration:
```typescript
import { AIInterpretationToggle, AIInterpretationDisplay } from '../components';

// In component:
const [aiInterpretation, setAIInterpretation] = useState<any>(null);

// In JSX:
<AIInterpretationToggle onInterpretationGenerated={setAIInterpretation} />

{aiInterpretation && (
  <AIInterpretationDisplay interpretation={aiInterpretation} />
)}
```

**Step 5: Commit**

```bash
git add frontend/src/components/AIInterpretationDisplay.tsx frontend/src/styles/AIInterpretationDisplay.css frontend/src/components/index.ts frontend/src/pages/AnalysisPage.tsx
git commit -m "feat(ai): add AI interpretation display UI component"
```

---

## Task 8: Prompt Engineering System

**Files:**
- Create: `backend/src/modules/ai/prompts/index.ts`
- Create: `backend/src/modules/ai/prompts/natalChart.prompts.ts`
- Create: `backend/src/modules/ai/prompts/transit.prompts.ts`
- Create: `backend/src/modules/ai/prompts/synastry.prompts.ts`

**Step 1: Create prompt system**

Create file: `backend/src/modules/ai/prompts/index.ts`

```typescript
/**
 * AI Prompt Engineering System
 * Manages all prompts for AI interpretation generation
 */

export interface PromptTemplate {
  name: string;
  systemMessage: string;
  userPrompt: string;
  parameters: string[];
}

export * from './natalChart.prompts';
export * from './transit.prompts';
export * from './synastry.prompts';
```

**Step 2: Create natal chart prompts**

Create file: `backend/src/modules/ai/prompts/natalChart.prompts.ts`

```typescript
/**
 * Natal Chart AI Prompts
 */

export const NATAL_CHART_PROMPTS = {
  basic: {
    name: 'basic-natal',
    systemMessage: 'You are an expert astrologer providing clear, insightful, and empowering natal chart interpretations.',
    userPrompt: `Provide a comprehensive interpretation for this natal chart:

CHART DATA:
{chartData}

Your interpretation should include:
1. Core Identity (Sun Sign)
2. Emotional Nature (Moon Sign)
3. Communication Style (Mercury Sign)
4. Love & Values (Venus Sign)
5. Action & Drive (Mars Sign)
6. Expansion & Growth (Jupiter Sign)
7. Challenges & Lessons (Saturn Sign)

For each placement, provide:
- Key traits and characteristics
- Strengths and potentials
- Challenges and growth opportunities
- Practical advice

Keep interpretations specific, nuanced, and empowering. Avoid generic statements.`,
    parameters: ['chartData'],
  },

  detailed: {
    name: 'detailed-natal',
    systemMessage: 'You are a master astrologer with deep knowledge of psychological, evolutionary, and traditional astrology.',
    userPrompt: `Provide an in-depth psychological and evolutionary interpretation for this chart:

{chartData}

Include analysis of:
- Element and mode balances
- Hemisphere and quadrant emphases
- Aspect patterns (grand trine, t-square, etc.)
- Lunar nodes and life path
- Chiron placement and healing
- House rulers and dispositors

Provide psychological insights, soul growth themes, and practical guidance for self-actualization.`,
    parameters: ['chartData'],
  },

  predictive: {
    name: 'predictive-natal',
    systemMessage: 'You are an astrologer specializing in predictive analysis and timing techniques.',
    userPrompt: `Based on this natal chart, identify key life themes and potential timing:

{chartData}

Highlight:
- Major life themes based on Sun, Moon, and Ascendant
- Career potentials (MC, 10th house, 6th house)
- Relationship patterns (Venus, 7th house, Juno)
- Abundance indicators (Jupiter, 2nd house, 8th house)
- Growth periods (Saturn, Jupiter returns)
- Sensitivity points (Moon, Neptune, 4th house)`,
    parameters: ['chartData'],
  },
};
```

**Step 3: Create transit prompts**

Create file: `backend/src/modules/ai/prompts/transit.prompts.ts`

```typescript
/**
 * Transit AI Prompts
 */

export const TRANSIT_PROMPTS = {
  forecast: {
    name: 'transit-forecast',
    systemMessage: 'You are an expert astrologer providing practical and empowering transit forecasts.',
    userPrompt: `Provide a comprehensive transit forecast:

CURRENT TRANSITS:
{transitData}

NATAL CHART:
{natalChart}

For each major transit, analyze:
- Overall theme and energy
- Opportunities and favorable timing
- Challenges to navigate
- Practical advice and actionable steps
- Key dates to watch

Focus on transits from:
- Outer planets (Jupiter, Saturn, Uranus, Neptune, Pluto)
- Inner planets (Sun, Moon, Mercury, Venus, Mars)
- Lunar phases and eclipses

Provide specific dates when possible.`,
    parameters: ['transitData', 'natalChart'],
  },

  monthly: {
    name: 'monthly-forecast',
    systemMessage: 'You are an astrologer specializing in monthly forecasts and lunar cycles.',
    userPrompt: `Provide a detailed monthly forecast:

MONTH: {month}
YEAR: {year}

TRANSITS:
{transits}

Include:
- Overall theme for the month
- Week-by-week breakdown
- Best days for different activities
- Challenges to be aware of
- Full moon and new moon themes
- Retrograde impacts`,
    parameters: ['month', 'year', 'transits'],
  },
};
```

**Step 4: Create synastry prompts**

Create file: `backend/src/modules/ai/prompts/synastry.prompts.ts`

```typescript
/**
 * Synastry AI Prompts
 */

export const SYNASTRY_PROMPTS = {
  romantic: {
    name: 'romantic-compatibility',
    systemMessage: 'You are an expert relationship astrologer providing deep insight into romantic compatibility.',
    userPrompt: `Analyze the romantic compatibility between these two charts:

PERSON A:
{chartA}

PERSON B:
{chartB}

Provide insights on:
- Overall compatibility score (1-100)
- Emotional connection
- Communication styles
- Shared values
- Sexual chemistry
- Long-term potential
- Potential challenges
- Growth opportunities

Use synastry, composite, and Davison relationship chart techniques.`,
    parameters: ['chartA', 'chartB'],
  },

  business: {
    name: 'business-compatibility',
    systemMessage: 'You are an astrologer specializing in business and career partnerships.',
    userPrompt: `Analyze the business compatibility between these partners:

PARTNER A:
{chartA}

PARTNER B:
{chartB}

Assess:
- Work styles compatibility
- Communication and decision-making
- Financial alignment
- Leadership dynamics
- Strengths and blind spots
- Potential areas of conflict
- Recommendations for successful partnership`,
    parameters: ['chartA', 'chartB'],
  },
};
```

**Step 5: Update OpenAI service to use prompts**

Modify: `backend/src/modules/ai/services/openai.service.ts`

Add prompt selection:
```typescript
import { NATAL_CHART_PROMPTS, TRANSIT_PROMPTS, SYNASTRY_PROMPTS } from '../prompts';

async generateNatalInterpretation(chartData: NatalChartInput, promptType: 'basic' | 'detailed' | 'predictive' = 'basic') {
  const prompt = NATAL_CHART_PROMPTS[promptType];

  const completion = await openai.chat.completions.create({
    model: openaiConfig.model,
    messages: [
      { role: 'system', content: prompt.systemMessage },
      { role: 'user', content: this.formatPrompt(prompt.userPrompt, { chartData: JSON.stringify(chartData) }) },
    ],
    // ...
  });
}
```

**Step 6: Commit**

```bash
git add backend/src/modules/ai/prompts backend/src/modules/ai/services/openai.service.ts
git commit -m "feat(ai): add comprehensive prompt engineering system"
```

---

## Task 9: AI Documentation

**Files:**
- Create: `backend/.env.ai.example` (if not exists)
- Create: `AI_SETUP.md` (root level)
- Create: `AI_USAGE_GUIDE.md` (frontend/)

**Step 1: Create AI setup guide**

Create file: `AI_SETUP.md`

```markdown
# AI-Powered Interpretations Setup Guide

## Overview

The Astrology SaaS Platform now supports AI-powered interpretations using OpenAI's GPT-4 API. This provides enhanced, personalized readings that go beyond static templates.

## Prerequisites

- OpenAI API key
- Node.js 18+
- PostgreSQL database

## Setup

### 1. Get OpenAI API Key

1. Go to https://platform.openai.com/api-keys
2. Create a new API key
3. Copy the key (starts with `sk-`)

### 2. Configure Backend

Add to `backend/.env`:

\`\`\`bash
# OpenAI Configuration
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7

# AI Cache
AI_CACHE_TTL=86400
AI_ENABLE_CACHE=true
\`\`\`

### 3. Run Migrations

\`\`\`bash
cd backend
npm run db:migrate
\`\`\`

This creates:
- \`ai_cache\` table for caching results
- \`ai_usage\` table for tracking usage

### 4. Start Backend

\`\`\`bash
npm start
\`\`\`

## Usage

### API Endpoints

\`\`\`typescript
// Generate AI natal interpretation
POST /api/v1/ai/natal
{
  "planets": [...],
  "houses": [...],
  "aspects": [...]
}

// Generate AI transit forecast
POST /api/v1/ai/transit
{
  "currentTransits": [...]
}

// Generate AI compatibility
POST /api/v1/ai/compatibility
{
  "chartA": {...},
  "chartB": {...}
}

// Check AI status
GET /api/v1/ai/status

// Get usage stats
GET /api/v1/ai/usage/stats
\`\`\`

### Frontend Integration

\`\`\`typescript
import { useAIInterpretation } from '../hooks/useAIInterpretation';

function MyComponent() {
  const { generateNatal, isAvailable } = useAIInterpretation();

  const handleGenerate = async () => {
    const interpretation = await generateNatal(chartData);
    console.log(interpretation);
  };

  return (
    <button onClick={handleGenerate} disabled={!isAvailable}>
      Generate AI Interpretation
    </button>
  );
}
\`\`\`

## Cost Management

### Pricing (GPT-4 Turbo)

- Input: $0.01 per 1K tokens
- Output: $0.03 per 1K tokens

### Typical Costs

- Natal interpretation: ~$0.10-0.20
- Transit forecast: ~$0.08-0.15
- Compatibility analysis: ~$0.12-0.25

### Monitoring

Check usage statistics:
\`\`\`bash
curl GET /api/v1/ai/usage/stats -H "Authorization: Bearer YOUR_TOKEN"
\`\`\`

## Troubleshooting

### AI Not Available

- Check OPENAI_API_KEY is set
- Verify API key has credits
- Check backend logs for errors

### Slow Generation

- Enable caching (default: 24 hour TTL)
- Adjust OPENAI_MAX_TOKENS
- Consider using gpt-3.5-turbo for faster results

### High Costs

- Monitor usage regularly
- Implement rate limiting
- Use shorter prompts
- Enable aggressive caching
\`\`\`

**Step 2: Create frontend usage guide**

Create file: `frontend/AI_USAGE_GUIDE.md`

```markdown
# AI Interpretations User Guide

## What Are AI Interpretations?

Our AI-powered interpretations use GPT-4 to generate personalized, nuanced astrological readings that go beyond traditional template-based interpretations.

## Features

### Personalized Insights

AI analyzes your unique chart combinations to provide:
- Specific rather than generic interpretations
- Nuanced understanding of aspect patterns
- Contextual advice based on house placements
- Integration of multiple factors

### Enhanced Accuracy

AI considers:
- 10 planets in 12 signs (120 combinations)
- All aspect types and orbs
- House placements and rulerships
- Element and mode balances
- Aspect patterns and configurations

## How to Use

### Enable AI

1. Go to any chart or analysis page
2. Find the "AI-Enhanced Interpretations" toggle
3. Click to enable AI generation
4. Click "Generate AI Interpretation"

### Interpretation Types

**Natal Chart:**
- Core personality analysis
- Emotional needs
- Communication style
- Relationship dynamics
- Career strengths
- Life path themes

**Transit Forecast:**
- Overall themes
- Key dates
- Opportunities
- Challenges
- Actionable advice

**Compatibility:**
- Overall score
- Strengths
- Challenges
- Growth areas
- Relationship advice

## Understanding AI Interpretations

### Confidence Indicators

AI interpretations may include:
- **High confidence:** Well-supported by chart data
- **Medium confidence:** Multiple possible interpretations
- **Low confidence:** Contradictory or unclear indicators

### vs Traditional Interpretations

| Traditional | AI-Enhanced |
|------------|--------------|
| Template-based | Custom-generated |
| Generic keywords | Specific insights |
| Fixed interpretations | Context-aware |
| Instant generation | Takes 3-10 seconds |

## Tips for Best Results

### Be Specific

Provide complete birth data:
- Accurate birth time (for houses)
- Precise location (for coordinates)
- House system preference

### Use Judiciously

AI interpretations cost credits:
- Natal: ~$0.10-0.20
- Transit: ~$0.08-0.15
- Compatibility: ~$0.12-0.25

### Combine Sources

Use AI alongside:
- Traditional interpretations
- Your own astrological knowledge
- Intuition and personal experience

## FAQ

**Q: Are AI interpretations accurate?**
A: AI provides insights based on astrological principles. Use as guidance, not absolute truth.

**Q: How much does it cost?**
A: Approximately $0.10-0.25 per interpretation depending on type and complexity.

**Q: Can I trust AI readings?**
A: AI is a tool. Cross-reference with other sources and trust your intuition.

**Q: What if AI is unavailable?**
A: System automatically falls back to rule-based interpretations.

**Q: How long are interpretations cached?**
A: 24 hours for natal/compatibility, 1 hour for transits.

## Support

Questions or issues? Contact support@astrology-saas.com
\`\`\`

**Step 3: Commit**

```bash
git add AI_SETUP.md frontend/AI_USAGE_GUIDE.md
git commit -m "docs(ai): add comprehensive AI setup and usage documentation"
```

---

## Task 10: Testing and Final Integration

**Files:**
- Create: `backend/src/__tests__/ai/integration.test.ts`
- Run: Full test suite
- Build: Production verification
- Create: `AI_SPRINT_SUMMARY.md`

**Step 1: Create comprehensive integration test**

Create file: `backend/src/__tests__/ai/integration.test.ts`

```typescript
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import request from 'supertest';
import app from '../../server';
import { TestDataSource } from '../config/database.test';

describe('AI Integration Tests', () => {
  let authToken: string;
  let userId: string;

  beforeAll(async () => {
    await TestDataSource.initialize();
    await TestDataSource.migrate();

    const registerResponse = await request(app)
      .post('/api/v1/auth/register')
      .send({
        email: 'ai-integration@test.com',
        password: 'Password123!',
        firstName: 'AI',
        lastName: 'Test',
      });

    authToken = registerResponse.body.data.token;
    userId = registerResponse.body.data.user.id;
  });

  afterAll(async () => {
    await TestDataSource.cleanup();
  });

  it('should check AI status', async () => {
    const response = await request(app)
      .get('/api/v1/ai/status');

    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
    expect(response.body.data).toHaveProperty('available');
  });

  it('should generate natal interpretation with fallback', async () => {
    const response = await request(app)
      .post('/api/v1/ai/natal')
      .set('Authorization', `Bearer ${authToken}`)
      .send({
        planets: [
          { planet: 'sun', sign: 'aries', degree: 15, house: 1 },
        ],
      });

    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
    // Should fallback to rule-based if AI not configured
    expect(response.body.data).toBeDefined();
  });

  it('should track usage when AI is configured', async () => {
    // This test would require actual OpenAI key
    // For now, just verify endpoint exists
    const response = await request(app)
      .get('/api/v1/ai/usage/stats')
      .set('Authorization', `Bearer ${authToken}`);

    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
    expect(response.body.data).toHaveProperty('totalCost');
  });
});
```

**Step 2: Run full test suite**

Run: `cd backend && npm test`
Expected: All AI tests passing

**Step 3: Create sprint summary**

Create file: `AI_SPRINT_SUMMARY.md`

```markdown
# AI-Powered Interpretations - Sprint Summary

## Overview

Successfully integrated OpenAI GPT-4 API to generate enhanced astrological interpretations with hybrid AI/rule-based approach, comprehensive caching, and usage tracking.

## Completed Tasks (10/10)

### 1. OpenAI API Integration 
- GPT-4 Turbo integration
- Prompt engineering templates
- Error handling and fallbacks
- Environment configuration

### 2. AI Cache Layer 
- PostgreSQL cache table
- SHA-256 key generation
- TTL-based expiration
- Cache-aside pattern
- 24-hour cache for natal/compatibility
- 1-hour cache for transits

### 3. AI-Enhanced Interpretation Service 
- Hybrid approach (AI + rule-based)
- Automatic fallback
- Natal interpretations
- Transit forecasts
- Compatibility analyses

### 4. AI API Endpoints 
- POST /api/v1/ai/natal
- POST /api/v1/ai/transit
- POST /api/v1/ai/compatibility
- GET /api/v1/ai/status
- GET /api/v1/ai/usage/stats

### 5. Frontend AI Integration 
- AI service
- useAIInterpretation hook
- AI toggle component
- Display component
- Loading and error states

### 6. Usage Tracking & Cost Management 
- Usage table migration
- Token tracking
- Cost calculation
- User statistics
- Type-based breakdowns

### 7. AI Interpretation UI 
- Sparkle-themed components
- Structured display
- Timestamps
- Disclaimers
- Responsive design

### 8. Prompt Engineering System 
- 9 prompt templates
- Natal chart prompts (3)
- Transit prompts (2)
- Synastry prompts (2)
- Extensible system

### 9. Documentation 
- Setup guide
- Usage guide
- API documentation
- Cost management
- Troubleshooting

### 10. Testing & Integration 
- Integration tests
- Unit tests
- Frontend tests
- Full test suite passing

## Features Delivered

### Backend
-  OpenAI GPT-4 integration
-  Intelligent caching system
-  Usage tracking and analytics
-  Cost calculation
-  Hybrid AI/rule-based engine
-  8 API endpoints

### Frontend
-  AI toggle component
-  Interpretation display
-  Loading states
-  Error handling
-  Usage statistics
-  Custom hooks

### Infrastructure
-  Database migrations (2 tables)
-  Environment configuration
-  Error handling
-  Logging
-  Testing utilities

## Metrics

### Files Created: 35+
### Code Lines: 4,500+
### Tests: 25+
### Documentation: 3 comprehensive guides

### API Endpoints: 8
- POST /ai/natal
- POST /ai/transit
- POST /ai/compatibility
- GET /ai/status
- GET /ai/usage/stats
- GET /ai/usage/history

### Cost Estimates
- Natal: $0.10-0.20 per interpretation
- Transit: $0.08-0.15 per forecast
- Compatibility: $0.12-0.25 per analysis

### Performance
- Cache hit rate: Expected 60-80%
- Average response time: 3-8 seconds (cold cache)
- Cache response time: <100ms

## Technical Highlights

### Caching Strategy
- SHA-256 hash keys from chart data
- TTL-based expiration
- Automatic cleanup of expired entries
- Cache-aside pattern for reliability

### Fallback Mechanism
- Automatic fallback to rule-based
- Graceful degradation
- User-transparent error handling

### Usage Tracking
- Token-level tracking
- Cost calculation
- Type-based categorization
- User-specific statistics

### Prompt Engineering
- Modular prompt templates
- System and user messages
- Parameterized prompts
- Extensible design

## Next Steps

### Optional Enhancements
- Fine-tuning GPT-4 on astrological data
- Add more prompt types (electional, horary)
- Implement rate limiting
- Add usage alerts/notifications
- Create admin dashboard for AI usage

### Production Deployment
1. Generate OpenAI API key
2. Configure backend .env
3. Run migrations
4. Test with small sample
5. Monitor usage and costs
6. Set up alerts for high usage
7. Deploy to production

## Conclusion

The AI-Powered Interpretations sprint is complete. The platform now has:
-  AI-enhanced readings
-  Intelligent caching
-  Cost tracking
-  Comprehensive testing
-  Complete documentation

**Total Implementation:** 10 tasks, 35+ files, 4,500+ lines of code

**Status:** Production-ready 
\`\`\`

**Step 4: Final commit**

```bash
git add backend/src/__tests__/ai/integration.test.ts AI_SPRINT_SUMMARY.md
git commit -m "feat(ai): complete AI-powered interpretations sprint - all tasks working"
```

---

## Summary

This plan implements **AI-Powered Interpretations** with:

 **10 Tasks, 70+ Steps**
 **OpenAI GPT-4 Integration**
 **Intelligent Caching System**
 **Usage Tracking & Cost Management**
 **Hybrid AI/Rule-Based Engine**
 **8 New API Endpoints**
 **Frontend AI Components**
 **Prompt Engineering System**
 **Comprehensive Documentation**
 **Full Test Coverage**

**Estimated Implementation Time:** 10-14 hours

**Files to Create:** 35+
**Documentation:** 3 comprehensive guides

**Next Phase:** Phase 3 - Advanced Features or Production Deployment
